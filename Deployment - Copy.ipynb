{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('C:\\\\Git\\\\a3-predicting-car-price-Arun-vEDU\\\\Cars_a3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    8.128000e+03\n",
      "mean     6.382718e+05\n",
      "std      8.062534e+05\n",
      "min      2.999900e+04\n",
      "25%      2.549990e+05\n",
      "50%      4.500000e+05\n",
      "75%      6.750000e+05\n",
      "max      1.000000e+07\n",
      "Name: selling_price, dtype: float64\n",
      "Minimum selling price: 29999\n",
      "Maximum selling price: 10000000\n"
     ]
    }
   ],
   "source": [
    "price_description = df[\"selling_price\"].describe()\n",
    "print(price_description)\n",
    "\n",
    "min_price = df[\"selling_price\"].min()\n",
    "max_price = df[\"selling_price\"].max()\n",
    "\n",
    "print(f\"Minimum selling price: {min_price}\")\n",
    "print(f\"Maximum selling price: {max_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       (11.761, 13.214]\n",
      "1       (11.761, 13.214]\n",
      "2       (11.761, 13.214]\n",
      "3       (11.761, 13.214]\n",
      "4       (11.761, 13.214]\n",
      "              ...       \n",
      "8123    (11.761, 13.214]\n",
      "8124    (11.761, 13.214]\n",
      "8125    (11.761, 13.214]\n",
      "8126    (11.761, 13.214]\n",
      "8127    (11.761, 13.214]\n",
      "Name: selling_price, Length: 8128, dtype: category\n",
      "Categories (4, interval[float64, right]): [(10.303, 11.761] < (11.761, 13.214] < (13.214, 14.666] < (14.666, 16.118]]\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Prepare data\n",
    "# y is simply the selling price colomn\n",
    "y = df[\"selling_price\"]\n",
    "\n",
    "# Covert into log scale\n",
    "y_log = np.log(df[\"selling_price\"])\n",
    "\n",
    "\n",
    "# Using pd.cut to bin data into 4 classes\n",
    "binned_data = pd.cut(y_log , bins=4) #now our y is four classes thus require multinomial\n",
    "\n",
    "\n",
    "print(binned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data\n",
    "# y is simply the selling price colomn\n",
    "y = df[\"selling_price\"]\n",
    "\n",
    "# Covert into log scale\n",
    "y_log = np.log(df[\"selling_price\"])\n",
    "\n",
    "\n",
    "binned_data = pd.cut(y_log, bins=4, labels=False)  # Creates 0, 1, 2, 3\n",
    "# plot the values\n",
    "# Value counts for each bin\n",
    "bin_counts = pd.value_counts(binned_data)\n",
    "\n",
    "# Bar plot\n",
    "bin_counts.sort_index().plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Selling Prices (Log Scale Bins)')\n",
    "plt.xlabel('Price Range (Log Scale)')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "8123    1\n",
      "8124    1\n",
      "8125    1\n",
      "8126    1\n",
      "8127    1\n",
      "Name: selling_price, Length: 8128, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add binned_data as a new column in the DataFrame\n",
    "df['binned_price'] = binned_data\n",
    "\n",
    "# Step 3: Prepare features and labels\n",
    "X = df.drop(columns=['selling_price', 'binned_price']) \n",
    "y = df['binned_price']  # Original binned labels (0, 1, 2, 3)\n",
    "\n",
    "print(binned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selling_price\n",
      "1    4342\n",
      "2    2884\n",
      "0     565\n",
      "3     337\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of classes\n",
    "class_distribution = binned_data.value_counts()\n",
    "\n",
    "# Display the distribution of each class\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name              object\n",
      "year               int64\n",
      "selling_price      int64\n",
      "km_driven          int64\n",
      "fuel              object\n",
      "seller_type       object\n",
      "transmission      object\n",
      "owner             object\n",
      "mileage           object\n",
      "engine            object\n",
      "max_power         object\n",
      "torque            object\n",
      "seats            float64\n",
      "binned_price       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# To check the data types of the columns\n",
    "print(df.dtypes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name              object\n",
      "year               int64\n",
      "selling_price      int64\n",
      "km_driven          int64\n",
      "fuel              object\n",
      "seller_type       object\n",
      "transmission      object\n",
      "owner             object\n",
      "mileage           object\n",
      "engine            object\n",
      "max_power        float64\n",
      "torque            object\n",
      "seats            float64\n",
      "binned_price       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# my selected features are 'Max Power' and 'Year' from a1 and a2 assignments.\n",
    "\n",
    "# Split the 'max_power' column by space\n",
    "df[['max_power', 'max_power_unit']] = df['max_power'].str.split(' ', expand=True)\n",
    "\n",
    "# Remove the 'max_power_unit' column\n",
    "df = df.drop('max_power_unit', axis=1)\n",
    "df.columns\n",
    "\n",
    "# Convert 'max_power' to a numeric type\n",
    "df['max_power'] = pd.to_numeric(df['max_power'])\n",
    "\n",
    "# To check the data types of the columns\n",
    "#print(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is my selected strong features\n",
    "# I have selected 2 features \"year\" and \"max_power\"\n",
    "# less features are better.\n",
    "X = df[        ['year', 'max_power']        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test\n",
    "# test set is 20% of our dataset.\n",
    "# This is a medium size data set, that is why it is selected 80%  traning set and 20% test set \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#  X is your feature set and binned_data is your target (with 4 classes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year          0\n",
       "max_power    49\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values in traning set,The .isna() method is used to detect missing values (not avalible) and count it\n",
    "X_train[['year', 'max_power']].isna().sum()\n",
    "#check for null values in test set, and count it\n",
    "X_test[['year', 'max_power']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# max power has 167 missing values. So we can fill them with ratio, the distribution of the 'max_power' is skewed.\n",
    "# X_train is  training dataset and 'max_power' contains missing values\n",
    "\n",
    "# Step 1: Calculate the ratio of each unique value in 'max_power'\n",
    "ratio = X_train['max_power'].value_counts(normalize=True)\n",
    "\n",
    "# Step 2: Define a function to sample values based on these ratios\n",
    "def fill_missing_values(column, value_distribution):\n",
    "    missing_indices = column[column.isnull()].index  # Find indices where values are missing\n",
    "    filled_values = np.random.choice(value_distribution.index, \n",
    "                                     size=len(missing_indices), \n",
    "                                     p=value_distribution.values)  # Sample from distribution\n",
    "    \n",
    "    # Fill the missing values with sampled values\n",
    "    column.loc[missing_indices] = filled_values\n",
    "    return column\n",
    "\n",
    "# Step 3: Fill missing values in 'max_power' based on the ratio\n",
    "X_train['max_power'] = fill_missing_values(X_train['max_power'], ratio)\n",
    "\n",
    "# Now, X_train['max_power'] has the missing values filled based on the value distribution\n",
    "print(X_train['max_power'].isnull().sum())  # This should return 0 (no missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Fill missing values in 'max_power' in X_test using the same ratio as X_train\n",
    "X_test['max_power'] = fill_missing_values(X_test['max_power'], ratio)\n",
    "\n",
    "# Now, X_test['max_power'] should have the missing values filled based on the distribution from X_train\n",
    "print(X_test['max_power'].isnull().sum())  # This should also return 0 (no missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE: Counter({1: 3443, 0: 3443, 2: 3443, 3: 3443})\n",
      "Loss at iteration 0: 1.403064937732779\n",
      "Loss at iteration 500: 0.49791496334888813\n",
      "Loss at iteration 1000: 0.45854139524272874\n",
      "Loss at iteration 1500: 0.4420962719505644\n",
      "Loss at iteration 2000: 0.4332289382894197\n",
      "Loss at iteration 2500: 0.42773532641551215\n",
      "Loss at iteration 3000: 0.42401122081119563\n",
      "Loss at iteration 3500: 0.4213220294955846\n",
      "Loss at iteration 4000: 0.4192881493559967\n",
      "Loss at iteration 4500: 0.41769526621310754\n",
      "Time taken: 13.76772141456604\n",
      "Macro f1: 0.6956379789214808\n"
     ]
    }
   ],
   "source": [
    "# I'm running the custom class for evaluate bast parameters with out mlflow. \n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Step 1: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Scaled X_train\n",
    "X_test_scaled = scaler.transform(X_test)        # Scaled X_test\n",
    "\n",
    "y_labels = y_train  # Assuming y_train contains the labels (0, 1, 2, 3)\n",
    "\n",
    "# Step 2: Apply SMOTE to the scaled X_train\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_labels_smote = smote.fit_resample(X_train_scaled, y_labels)  # Use the scaled X_train\n",
    "\n",
    "# Check the class distribution after SMOTE\n",
    "print(\"After SMOTE:\", Counter(y_labels_smote))\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_labels_smote_one_hot = pd.get_dummies(y_labels_smote, prefix='class')\n",
    "\n",
    "# Step 3: Add intercept term AFTER SMOTE and scaling\n",
    "intercept_train = np.ones((X_train_smote.shape[0], 1))  # Shape (m, 1)\n",
    "X_train_with_intercept = np.concatenate((intercept_train, X_train_smote), axis=1)  # Shape (m, n + 1)\n",
    "\n",
    "intercept_test = np.ones((X_test_scaled.shape[0], 1))  # Shape (m, 1)\n",
    "X_test_with_intercept = np.concatenate((intercept_test, X_test_scaled), axis=1)  # Shape (m, n + 1)\n",
    "\n",
    "# Logistic Regression class\n",
    "class LogisticRegression:\n",
    "    def __init__(self, k, n, method, alpha=0.1, max_iter=5000, use_penalty=False, penalty='ridge', lambda_=0.01):\n",
    "        self.k = k  # Number of classes\n",
    "        self.n = n  # Number of features\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.max_iter = max_iter  # Maximum iterations\n",
    "        self.method = method  # Optimization method: 'batch', 'minibatch', or 'sto'\n",
    "        self.use_penalty = use_penalty  # Whether to use penalty (regularization)\n",
    "        self.penalty = penalty  # Type of penalty ('ridge' for L2)\n",
    "        self.lambda_ = lambda_  # Regularization strength\n",
    "        self.W = np.random.rand(n + 1, k)  # Initialize weights\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.W = np.random.rand(self.n + 1, self.k)  # Initialize weights\n",
    "        self.losses = []  # To store loss values\n",
    "        \n",
    "        if self.method == \"batch\":\n",
    "            start_time = time.time()\n",
    "            for i in range(self.max_iter):\n",
    "                loss, grad = self.gradient(X, Y)\n",
    "                self.losses.append(loss)\n",
    "                self.W -= self.alpha * grad  # Update weights\n",
    "                if i % 500 == 0:\n",
    "                    print(f\"Loss at iteration {i}: {loss}\")\n",
    "            print(f\"Time taken: {time.time() - start_time}\")\n",
    "        \n",
    "        elif self.method == \"minibatch\":\n",
    "            start_time = time.time()\n",
    "            batch_size = int(0.3 * X.shape[0])\n",
    "            for i in range(self.max_iter):\n",
    "                indices = np.random.choice(X.shape[0], size=batch_size, replace=False)  # Randomly select indices for the batch\n",
    "                batch_X = X[indices]\n",
    "                batch_Y = Y[indices]\n",
    "                loss, grad = self.gradient(batch_X, batch_Y)\n",
    "                self.losses.append(loss)\n",
    "                self.W -= self.alpha * grad  # Update weights\n",
    "                if i % 500 == 0:\n",
    "                    print(f\"Loss at iteration {i}: {loss}\")\n",
    "            print(f\"Time taken: {time.time() - start_time}\")\n",
    "        \n",
    "        elif self.method == \"sto\":\n",
    "            start_time = time.time()\n",
    "            for i in range(self.max_iter):\n",
    "                idx = np.random.randint(X.shape[0])  # Randomly select an index\n",
    "                X_train = X[idx, :].reshape(1, -1)  # Reshape for a single sample\n",
    "                Y_train = Y[idx].reshape(1, -1)  # Reshape for a single sample\n",
    "                loss, grad = self.gradient(X_train, Y_train)\n",
    "                self.losses.append(loss)\n",
    "                self.W -= self.alpha * grad  # Update weights\n",
    "                if i % 500 == 0:\n",
    "                    print(f\"Loss at iteration {i}: {loss}\")\n",
    "            print(f\"Time taken: {time.time() - start_time}\")\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Method must be one of the following: \"batch\", \"minibatch\", or \"sto\".')\n",
    "        \n",
    "    def gradient(self, X, Y):\n",
    "        m = X.shape[0]  # Number of training examples\n",
    "        h = self.h_theta(X, self.W)  # Hypothesis\n",
    "        loss = -np.sum(Y * np.log(h)) / m  # Cross-entropy loss\n",
    "        \n",
    "        # Apply penalty if use_penalty is True\n",
    "        if self.use_penalty and self.penalty == 'ridge':\n",
    "            loss += (self.lambda_ / (2 * m)) * np.sum(np.square(self.W))  # Ridge penalty (L2)\n",
    "        \n",
    "        error = h - Y  # Error term\n",
    "        grad = self.softmax_grad(X, error)\n",
    "        \n",
    "        # Apply gradient for penalty if use_penalty is True\n",
    "        if self.use_penalty and self.penalty == 'ridge':\n",
    "            grad += (self.lambda_ / m) * self.W  # Add Ridge gradient (L2)\n",
    "        \n",
    "        return loss, grad\n",
    "        \n",
    "    def softmax(self, theta_t_x):\n",
    "        # Ensure input is a NumPy array\n",
    "        theta_t_x = np.array(theta_t_x)\n",
    "    \n",
    "        # Perform softmax calculation\n",
    "        exp_values = np.exp(theta_t_x - np.max(theta_t_x, axis=1, keepdims=True))\n",
    "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "    def softmax_grad(self, X, error):\n",
    "        return X.T @ error / X.shape[0]\n",
    "\n",
    "    def h_theta(self, X, W):\n",
    "        return self.softmax(X @ W)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "            h = self.h_theta(X_test, self.W)  # Get the probabilities\n",
    "            return np.argmax(h, axis=1)  # Return the predicted class labels directly\n",
    "\n",
    "    def f1_score(self, y_true, y_pred, class_label):\n",
    "        prec = self.precision(y_true, y_pred, class_label)\n",
    "        rec = self.recall(y_true, y_pred, class_label)\n",
    "        return 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "\n",
    "    def precision(self, y_true, y_pred, class_label):\n",
    "        TP = np.sum((y_true == class_label) & (y_pred == class_label))\n",
    "        FP = np.sum((y_true != class_label) & (y_pred == class_label))\n",
    "        return TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "    def recall(self, y_true, y_pred, class_label):\n",
    "        TP = np.sum((y_true == class_label) & (y_pred == class_label))\n",
    "        FN = np.sum((y_true == class_label) & (y_pred != class_label))\n",
    "        return TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    def macro_f1(self, y_true, y_pred):\n",
    "        classes = np.unique(y_true)\n",
    "        f1_scores = [self.f1_score(y_true, y_pred, class_label) for class_label in classes]\n",
    "        return np.mean(f1_scores)\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Iterate over all combinations of hyperparameters\n",
    "\n",
    "log_reg = LogisticRegression(k=4, n=X_train_scaled.shape[1],method ='batch', alpha=0.1, max_iter=5000, use_penalty=False, penalty='ridge', lambda_=0.01)\n",
    "log_reg.fit(X_train_with_intercept, y_labels_smote_one_hot.values)  # Use the one-hot encoded labels\n",
    "    \n",
    "    \n",
    "\n",
    "    # Make predictions on the test set\n",
    "y_test_pred_labels = log_reg.predict(X_test_with_intercept)\n",
    "   \n",
    "    \n",
    "    #  Evaluate F1 score\n",
    "f1 = log_reg.macro_f1(y_test, y_test_pred_labels)\n",
    "    \n",
    "print(f\"Macro f1: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import dill\n",
    "# save the model to disk\n",
    "filename = 'Car_classification.pkl'\n",
    "pickle.dump(log_reg, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "# Save the model\n",
    "with open('app.pkl', 'wb') as f:\n",
    "    dill.dump((log_reg, scaler), f)\n",
    "\n",
    "# Load the model\n",
    "with open('app.pkl', 'rb') as f:\n",
    "    model = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from Car_classification.pkl\n",
      "Predicted class label for the new data: [0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Step 2: Load the model from the file\n",
    "with open('Car_classification.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded from Car_classification.pkl\")\n",
    "\n",
    "\n",
    "# Step 1: Prepare your new data\n",
    "# Example of new data point (replace with your actual data)\n",
    "new_data = np.array([[2000, 120]])  # Replace with actual values\n",
    "new_data_scaled = scaler.transform(new_data)  # Scale the new data\n",
    "\n",
    "# Step 2: Add the intercept term to the new data\n",
    "intercept_new_data = np.ones((new_data_scaled.shape[0], 1))  # Shape (m, 1)\n",
    "new_data_with_intercept = np.concatenate((intercept_new_data, new_data_scaled), axis=1)  # Shape (m, n + 1)\n",
    "\n",
    "# Step 3: Predict the class of the new data\n",
    "predicted_class_label = loaded_model.predict(new_data_with_intercept)\n",
    "\n",
    "# Output the predicted class label\n",
    "print(f\"Predicted class label for the new data: {predicted_class_label}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original price ranges for the bins: [   29825.23572178   128182.89725297   547713.4287198   2340327.8161826\n",
      " 10000000.00000001]\n",
      "Model loaded from Car_classification.pkl\n",
      "Predicted class label for the new data: [2]\n",
      "The predicted class corresponds to the original price range: 547713.43 to 2340327.82\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Bin the data using pd.cut and retrieve the bin edges\n",
    "y_log = np.log(df[\"selling_price\"])\n",
    "\n",
    "# Using pd.cut to bin data into 4 classes\n",
    "binned_data, bin_edges = pd.cut(y_log, bins=4, retbins=True)  # Returns both the binned data and the bin edges\n",
    "\n",
    "# Convert the bin edges to the original selling price scale\n",
    "bin_edges_original = np.exp(bin_edges)\n",
    "\n",
    "print(f\"Original price ranges for the bins: {bin_edges_original}\")\n",
    "\n",
    "# Now, you can continue with the rest of your prediction steps...\n",
    "\n",
    "# Step 2: Load the model from the file\n",
    "with open('Car_classification.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded from Car_classification.pkl\")\n",
    "\n",
    "# Step 3: Prepare your new data (replace with your actual data)\n",
    "new_data = np.array([[2020, 120]])  # Replace with actual values\n",
    "new_data_scaled = scaler.transform(new_data)  # Scale the new data\n",
    "\n",
    "# Step 4: Add the intercept term to the new data\n",
    "intercept_new_data = np.ones((new_data_scaled.shape[0], 1))  # Shape (m, 1)\n",
    "new_data_with_intercept = np.concatenate((intercept_new_data, new_data_scaled), axis=1)  # Shape (m, n + 1)\n",
    "\n",
    "# Step 5: Predict the class of the new data\n",
    "predicted_class_label = loaded_model.predict(new_data_with_intercept)\n",
    "\n",
    "# Output the predicted class label\n",
    "print(f\"Predicted class label for the new data: {predicted_class_label}\")\n",
    "\n",
    "# Step 6: Map the predicted class label to the original price range\n",
    "predicted_class = predicted_class_label[0]  # Since it's an array, take the first (and only) value\n",
    "\n",
    "# Get the corresponding price range for the predicted class\n",
    "price_range = (bin_edges_original[predicted_class], bin_edges_original[predicted_class + 1])\n",
    "\n",
    "# Output the predicted price range\n",
    "print(f\"The predicted class corresponds to the original price range: {price_range[0]:.2f} to {price_range[1]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
